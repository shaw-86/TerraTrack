{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "R5x11YaIF9x2",
      "metadata": {
        "id": "R5x11YaIF9x2"
      },
      "source": [
        "<p>\n",
        "  <img src=\"https://raw.githubusercontent.com/shaw-86/TerraTrack/main/figures/logo.png\" alt=\"TerraTrack\" width=\"120\">\n",
        "</p>\n",
        "\n",
        "# TerraTrack ‚Äî Mapping Earth‚Äôs Motion in Pixels\n",
        "\n",
        "This notebook implements the **feature tracking component** of TerraTrack for detecting and monitoring slow-moving landslides using **Sentinel-2 imagery**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Bn8Xi8D5godG",
      "metadata": {
        "id": "Bn8Xi8D5godG"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <tr>\n",
        "    <td>\n",
        "      <a target=\"_blank\" href=\"https://github.com/lorenzonava96/TerraTrack/tree/main\">\n",
        "        <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "        View repository on GitHub\n",
        "      </a>\n",
        "    </td>\n",
        "    <td>\n",
        "      <a target=\"_blank\" href=\"https://github.com/lorenzonava96/TerraTrack/blob/main/notebooks/TerraTrack_v1.ipynb\" download>\n",
        "        <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />\n",
        "        Download notebook\n",
        "      </a>\n",
        "    </td>\n",
        "    <td>\n",
        "      <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" alt=\"Preprint logo\" />\n",
        "      <a href=\"https://egusphere.copernicus.org/preprints/2025/egusphere-2025-2795/egusphere-2025-2795.pdf\" target=\"_blank\">\n",
        "        <em>Preprint ‚Äì Open Discussion</em>\n",
        "      </a>\n",
        "    </td>\n",
        "    <td>\n",
        "      <img src=\"https://img.icons8.com/ios-filled/32/000000/youtube-play.png\" />\n",
        "      <em>Video tutorial (coming soon)</em>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lNhlSzSOgmPb",
      "metadata": {
        "collapsed": true,
        "id": "lNhlSzSOgmPb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/shaw-86/TerraTrack.git\n",
        "!pip uninstall earthengine-api -y\n",
        "!pip uninstall geemap -y\n",
        "!pip install -r TerraTrack/requirements.txt\n",
        "!pip install --upgrade earthengine-api geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LvPB1GpDrlGg",
      "metadata": {
        "id": "LvPB1GpDrlGg"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import exposure\n",
        "from datetime import datetime\n",
        "from scipy.ndimage import convolve\n",
        "from scipy.signal import medfilt\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import ee\n",
        "import geemap\n",
        "from TerraTrack.src import *\n",
        "\n",
        "output_dir = 'outputs'\n",
        "\n",
        "ee.Authenticate(auth_mode='notebook')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MFJnYfDerItV",
      "metadata": {
        "id": "MFJnYfDerItV"
      },
      "source": [
        "## **Initialize and Define Area of Interest (AoI)**\n",
        "\n",
        "This section initializes a `Map` instance using the `geemap` library and centers it on a global view with a satellite basemap. The map will help define the Area of Interest (AOI).\n",
        "\n",
        "### Instructions:\n",
        "1. Use the map tools on the left to draw a single rectangular box defining your AOI.\n",
        "2. Use the globe icon on the top left to search for specific locations if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "woZrRkTdL235",
      "metadata": {
        "id": "woZrRkTdL235"
      },
      "outputs": [],
      "source": [
        "# Create a Map instance\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Add a satellite basemap for visualization (similar to Google Earth)\n",
        "Map.add_basemap('HYBRID')\n",
        "\n",
        "# Center the map globally\n",
        "Map.setCenter(0, 0, 2)  # Center on the world with zoom level 2\n",
        "\n",
        "# Display the map for user interaction\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FrpwDQ4r1sct",
      "metadata": {
        "id": "FrpwDQ4r1sct"
      },
      "source": [
        "### **Filtering and Processing Sentinel-2 Imagery**\n",
        "This block sets parameters to filter and process Sentinel-2 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oMW3qkYorlX3",
      "metadata": {
        "id": "oMW3qkYorlX3"
      },
      "outputs": [],
      "source": [
        "# Define filtering parameters\n",
        "SUMMER_START = '-01-01'       # Start of seasonal filter (MM-DD)\n",
        "SUMMER_END = '-12-30'         # End of seasonal filter (MM-DD)\n",
        "START_YEAR = 2015             # First year to include\n",
        "END_YEAR = 2025               # Last year to include\n",
        "start_date = None     # Optional: remove images before this date ('YYYY-MM-DD')\n",
        "final_date = None     # Optional: limit images up to this date ('YYYY-MM-DD')\n",
        "\n",
        "# Image and mask filtering\n",
        "CLOUD_COVER_MAX = 50          # Max allowable cloud cover per tile (%)\n",
        "N_PER_YEAR = 5               # Max number of images sampled per year\n",
        "mask_water = False            # Enable NDWI-based water masking\n",
        "check_clouds = True           # Remove images with too much cloud in the ROI\n",
        "cloud_threshold = 5           # Max allowable cloud cover in ROI (%)\n",
        "check_snow = True            # Remove images with excessive snow in ROI\n",
        "snow_threshold = 5            # Max allowable snow cover in ROI (%)\n",
        "\n",
        "# Define region of interest from drawn features\n",
        "roi = ee.FeatureCollection(Map.draw_features).geometry()\n",
        "\n",
        "# Process Sentinel-2 imagery and extract terrain data\n",
        "final_collection, morpho = process_sentinel2_data(\n",
        "    roi, START_YEAR, END_YEAR, SUMMER_START, SUMMER_END,\n",
        "    cloud_cover_max=CLOUD_COVER_MAX,\n",
        "    n_per_year=N_PER_YEAR,\n",
        "    mask_water=mask_water,\n",
        "    check_clouds=check_clouds,\n",
        "    cloud_threshold=cloud_threshold,\n",
        "    check_snow=check_snow,\n",
        "    snow_threshold=snow_threshold,\n",
        "    start_date=start_date,\n",
        "    final_date=final_date\n",
        ")\n",
        "\n",
        "# Print the size of the filtered image collection\n",
        "print(\"Final collection size:\", final_collection.size().getInfo())\n",
        "\n",
        "# Print acquisition dates of selected images\n",
        "dates = final_collection.aggregate_array('system:time_start') \\\n",
        "    .map(lambda d: ee.Date(d).format('YYYY-MM-dd')).getInfo()\n",
        "\n",
        "print(\"Acquisition dates in final_collection:\")\n",
        "for d in dates:\n",
        "    print(d)\n",
        "\n",
        "print(\"Processing completed. Final collection and morpho are ready to be downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ORwa66YM-HMA",
      "metadata": {
        "id": "ORwa66YM-HMA"
      },
      "source": [
        "### **Downloading Processed Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B63tSIo3rlar",
      "metadata": {
        "id": "B63tSIo3rlar"
      },
      "outputs": [],
      "source": [
        "# Set up directory for output files\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Generate a composite image by stacking the B8 band across the image collection\n",
        "composite_image = final_collection.select('SR_B5').toBands()\n",
        "composite_output_path = os.path.join(output_dir, 'S2_Composite.tif')\n",
        "\n",
        "# Download S2 Composite\n",
        "geemap.download_ee_image(composite_image, composite_output_path, scale=None, crs=None, region=roi.getInfo())\n",
        "print(\"Composite image downloaded.\")\n",
        "\n",
        "# Download morpho\n",
        "composite_output_path = os.path.join(output_dir, 'morpho.tif')\n",
        "geemap.download_ee_image(morpho, composite_output_path, scale=None, crs=None, region=roi.getInfo())\n",
        "\n",
        "print(\"DEM, Slope, and Aspect downloaded.\")\n",
        "\n",
        "# Aggregate metadata arrays for the entire collection in a single query\n",
        "image_ids = final_collection.aggregate_array('system:index').getInfo()\n",
        "dates = final_collection.aggregate_array('system:time_start').map(lambda t: ee.Date(t).format('YYYY-MM-dd')).getInfo()\n",
        "cloud_covers = final_collection.aggregate_array('CLOUD_COVER_LAND').getInfo()\n",
        "orbits = final_collection.aggregate_array('TARGET_WRS_PATH').getInfo()\n",
        "tile_ids = final_collection.aggregate_array('LANDSAT_PRODUCT_ID').getInfo()\n",
        "\n",
        "# Combine into a dictionary for DataFrame creation\n",
        "metadata = {\n",
        "    'Image_ID': image_ids,\n",
        "    'Date': dates,\n",
        "    'Cloud_Cover': cloud_covers,\n",
        "    'Orbit_Number': orbits,\n",
        "    'Tile_ID': tile_ids\n",
        "}\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "metadata_df = pd.DataFrame(metadata)\n",
        "# Clean the ID column\n",
        "metadata_df[\"Image_ID\"] = metadata_df[\"Image_ID\"].str.replace(r'^.*?(\\d{8}T\\d{6}.*)$', r'\\1', regex=True)\n",
        "metadata_csv_path = os.path.join(output_dir, 'S2_Metadata.csv')\n",
        "metadata_df.to_csv(metadata_csv_path, index=False)\n",
        "\n",
        "print(\"Metadata saved to CSV file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zUcIuMVfOmbR",
      "metadata": {
        "id": "zUcIuMVfOmbR"
      },
      "source": [
        "### **Processing Sentinel-2 Composite**\n",
        "This block processes the **Sentinel-2 composite image**, allowing the user to choose how images are selected:  \n",
        "\n",
        "- **Selection Method (`selection_method`)**:  \n",
        "  - `\"manual\"` ‚Äì User manually selects images for the composite.  \n",
        "  - `\"auto\"` ‚Äì Keeps all the images.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1xeuoEG2loba",
      "metadata": {
        "id": "1xeuoEG2loba"
      },
      "outputs": [],
      "source": [
        "process_composite_image(output_dir=output_dir, selection_method=\"auto\")  #auto, manual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q61Xzbpb-wS6",
      "metadata": {
        "id": "q61Xzbpb-wS6"
      },
      "source": [
        "### **Preprocessing Sentinel-2 Composite**\n",
        "This block **opens, processes, and prepares** the Sentinel-2 composite for analysis.  \n",
        "\n",
        "- **Processing Method (`method`)**:  \n",
        "  - `\"cross_corr\"` (**Recommended**) ‚Äì Provides accurate alignment with minimal noise.  \n",
        "  - `\"optical_flow\"` ‚Äì Can be very noisy and is generally not recommended.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d93cb75",
      "metadata": {
        "id": "2d93cb75",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Set feature tracking method: 'cross_corr' (NCC, PCC) or 'optical_flow'\n",
        "method = 'cross_corr'\n",
        "\n",
        "# Define preprocessing parameters\n",
        "preprocess_params = {\n",
        "    \"method\": method\n",
        "}\n",
        "\n",
        "# Load the composite image stack (uint8, filtered)\n",
        "with rasterio.open(f'{output_dir}/S2_Composite_Filtered_8bit.tif') as src:\n",
        "    num_bands = src.count\n",
        "    print(f\"üì¶ Number of bands in composite: {num_bands}\")\n",
        "\n",
        "    # Read the full stack: shape (bands, height, width)\n",
        "    orig = src.read()\n",
        "\n",
        "# Preprocess the image stack (e.g., normalize, filter)\n",
        "# Input shape: (bands, H, W) ‚Üí returns (H, W, bands)\n",
        "preprocessed_stack = preprocess_image_stack(orig, preprocess_params)\n",
        "\n",
        "# Transpose for visualization/processing: (H, W, bands)\n",
        "orig = np.transpose(orig, (1, 2, 0))\n",
        "print(f\"‚úÖ Original stack shape:     {orig.shape}\")\n",
        "print(f\"‚úÖ Preprocessed stack shape: {preprocessed_stack.shape}\")\n",
        "\n",
        "# Build a mask: 1 if a pixel is 0 in ANY band (e.g., masked out earlier), else 0\n",
        "zero_mask = np.any(orig == 0, axis=2).astype(int)\n",
        "\n",
        "# Apply the mask across the full stack: set masked pixels to NaN\n",
        "orig_masked = np.where(zero_mask[..., np.newaxis] == 1, np.nan, orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MPi2Uca9vn9K",
      "metadata": {
        "id": "MPi2Uca9vn9K"
      },
      "outputs": [],
      "source": [
        "### PLOT ###\n",
        "\n",
        "# Define the number of images to display\n",
        "num_images = min(5, orig.shape[2])\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(num_images, 2, figsize=(15, 2 * num_images))\n",
        "\n",
        "for i in range(num_images):\n",
        "    # Original image\n",
        "    axes[i, 0].imshow(orig[:, :, i], cmap='gray')\n",
        "    axes[i, 0].set_title(f'Original Image {i+1}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Processed image\n",
        "    axes[i, 1].imshow(preprocessed_stack[:, :, i], cmap='gray')\n",
        "    axes[i, 1].set_title(f'Processed Image {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11VevUya_uAG",
      "metadata": {
        "id": "11VevUya_uAG"
      },
      "source": [
        "### **Defining Date Pairs for Analysis**\n",
        "This block selects **valid date pairs** from metadata based on a **user-defined time separation range** (`min_separation` & `max_separation`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54bc7c7",
      "metadata": {
        "id": "f54bc7c7"
      },
      "outputs": [],
      "source": [
        "min_separation = 1 # in years\n",
        "max_separation = 5 # in years\n",
        "reference_date = None # YYYY-MM-DD in case of a known constraint motion at a given time (e.g. earthquake)\n",
        "\n",
        "dat1, dat2, separation, datax = define_date_pairs(f\"{output_dir}/Updated_Metadata.csv\",\n",
        "                                                  min_separation=min_separation,\n",
        "                                                  max_separation=max_separation,\n",
        "                                                  reference_date=reference_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd7f772",
      "metadata": {
        "id": "8bd7f772"
      },
      "source": [
        "# **Feature Tracking Core**\n",
        "\n",
        "### **Test on a Single Image Pair**\n",
        "This block tests tracking parameters on one image pair (`img1`: band 1, `img2`: band 35) to fine-tune before full-scale processing. Time separation between images affects detectability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92475de",
      "metadata": {
        "id": "f92475de"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# --- Select Image Pair from Stack ---\n",
        "# (Band indices: 0-based)\n",
        "img1 = preprocessed_stack[:, :, 1]\n",
        "img2 = preprocessed_stack[:, :, 20]\n",
        "\n",
        "# --- Feature Tracking Parameters ---\n",
        "method = 'block_matching'            # 'block_matching' or 'optical_flow'\n",
        "match_func = 'fft_pcc'               # 'fft_ncc', 'fft_pcc', 'phase_cross_corr', or 'median_dense_optical_flow'\n",
        "subpixel_method = 'parabolic'        # center_of_mass, parabolic, centroid, gaussian, os3, os5, os7, ipg, ensemble\n",
        "\n",
        "block_size = 16\n",
        "overlap = 0.6\n",
        "\n",
        "# --- Displacement Limits ---\n",
        "min_displacement = 0.1\n",
        "max_displacement = 5\n",
        "\n",
        "# --- Filtering Options ---\n",
        "filter_params = {\n",
        "    \"apply_magnitude_filter\": True,          # Remove displacements below/above thresholds\n",
        "    \"min_magnitude\": min_displacement,                      # Minimum accepted motion\n",
        "    \"max_magnitude\": max_displacement,       # Maximum accepted motion (usually block_size - 1)\n",
        "    \"apply_zero_mask_filter\": False,         # Exclude pixels masked in any image (e.g., water/clouds)\n",
        "    \"apply_deviation_filter\": False,         # Remove vectors far from statistical mean\n",
        "    \"std_factor\": 2.5,                       # Standard deviation threshold for deviation filter\n",
        "    \"apply_remove_median_displacement\": True,  # Subtract overall median motion (e.g., camera jitter)\n",
        "    \"apply_median_filter_step\": False,       # Smooth vectors using a median filter\n",
        "    \"filter_size\": 5,                        # Size of median filter kernel (if used)\n",
        "    \"apply_angular_coherence_filter\": False, # Remove vectors that don‚Äôt align with dominant motion\n",
        "    \"angular_threshold\": 50,                 # Max angular deviation (degrees)\n",
        "    \"smoothing_sigma\": 1,                    # Angular coherence smoothing parameter\n",
        "    \"apply_erratic_displacement_filter\": False,  # Remove isolated, noisy vectors\n",
        "    \"neighborhood_size\": 20,                 # Radius for local filtering\n",
        "    \"deviation_threshold\": 2.0,              # Threshold for local deviation\n",
        "    \"apply_pkr_filter\": True,                # Remove low-quality matches using PKR\n",
        "    \"pkr_threshold\": 1.3,                    # Minimum accepted peak-to-residual ratio\n",
        "    \"apply_snr_filter\": True,                # Remove low-confidence vectors based on SNR\n",
        "    \"snr_threshold\": 3,                      # Minimum signal-to-noise ratio\n",
        "}\n",
        "\n",
        "# --- Run Displacement Analysis ---\n",
        "start_time = time.time()\n",
        "\n",
        "u, v, feature_points, pkr, snr = displacement_analysis(\n",
        "    img1=img1,\n",
        "    img2=img2,\n",
        "    method=method,\n",
        "    block_size=block_size,\n",
        "    overlap=overlap,\n",
        "    match_func=match_func,\n",
        "    subpixel_method=subpixel_method,\n",
        "    zero_mask=zero_mask,\n",
        "    filter_params=filter_params,\n",
        "    plot=True,\n",
        "    arrow_scale=0.1\n",
        ")\n",
        "\n",
        "full_feature_points = feature_points  # Store full-resolution grid\n",
        "\n",
        "# --- Timing ---\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"BLOCK MATCHING ‚Äî Process completed in {elapsed_time:.2f} seconds (1 pair).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BvmuPi1O1qiJ",
      "metadata": {
        "id": "BvmuPi1O1qiJ"
      },
      "outputs": [],
      "source": [
        "# Estimate total processing time for all image pairs\n",
        "num_pairs = len(separation)  # List of valid date pairs (from earlier step)\n",
        "estimated_total_time = elapsed_time * num_pairs / 60  # in minutes\n",
        "\n",
        "print(f\"‚è±Ô∏è Estimated total processing time for {num_pairs} pairs: {estimated_total_time:.1f} minutes (with parallel computing it'll be faster)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4JO8n1i36sBu",
      "metadata": {
        "id": "4JO8n1i36sBu"
      },
      "source": [
        "### **Processing Image Pairs for Displacement Analysis**\n",
        "\n",
        "This block runs **feature tracking** across multiple image pairs using the selected method.\n",
        "\n",
        "---\n",
        "\n",
        "## üö® Recommendation\n",
        "**Disable all filters at this stage.**  \n",
        "Apply filtering **after processing all pairs** to avoid inconsistent results. Early filtering may discard useful data ‚Äî it's better to clean up with post-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c689b76",
      "metadata": {
        "id": "9c689b76",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# FT parameters\n",
        "method = 'block_matching' # block_matching, optical_flow\n",
        "match_func = 'fft_pcc'      # 'fft_ncc', 'fft_pcc', 'phase_cross_corr', or 'median_dense_optical_flow'\n",
        "subpixel_method='parabolic' # center_of_mass, parabolic, gaussian, os3, os5, os7, ipg, ensemble\n",
        "block_size = 16\n",
        "overlap = 0.6\n",
        "\n",
        "# Filter parameters must be all off here\n",
        "filter_params = {\n",
        "    \"apply_magnitude_filter\": False,\n",
        "    \"min_magnitude\": 0,\n",
        "    \"max_magnitude\": max_displacement,\n",
        "    \"apply_zero_mask_filter\": False,\n",
        "    \"apply_deviation_filter\": False,\n",
        "    \"std_factor\": 2.5,\n",
        "    \"apply_remove_median_displacement\": False,\n",
        "    \"apply_median_filter_step\": False,\n",
        "    \"filter_size\": 5,\n",
        "    \"apply_angular_coherence_filter\": False,\n",
        "    \"angular_threshold\": 50,\n",
        "    \"smoothing_sigma\": 1,\n",
        "    \"apply_erratic_displacement_filter\": False,\n",
        "    \"neighborhood_size\": 20,\n",
        "    \"deviation_threshold\": 2.0,\n",
        "    'apply_pkr_filter': False,\n",
        "    'pkr_threshold': 1.3,\n",
        "    'apply_snr_filter': False,\n",
        "    'snr_threshold': 3,\n",
        "}\n",
        "\n",
        "# Run the processing function\n",
        "results = process_image_pairs(\n",
        "    dat1=dat1,\n",
        "    dat2=dat2,\n",
        "    datax=datax,\n",
        "    preprocessed_stack=preprocessed_stack,\n",
        "    zero_mask=zero_mask,\n",
        "    filter_params=filter_params,\n",
        "    method=method,\n",
        "    block_size=block_size,\n",
        "    overlap=overlap,\n",
        "    match_func=match_func,\n",
        "    subpixel_method=subpixel_method,\n",
        "    max_workers=12,\n",
        "    parallel=True)\n",
        "\n",
        "print('FINALLY DONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x7XTDQrl7a9n",
      "metadata": {
        "id": "x7XTDQrl7a9n"
      },
      "source": [
        "### **Saving Raw Feature Tracking (FT) Output**\n",
        "This block **saves and loads** the raw **displacement results** from feature tracking.  \n",
        "\n",
        "üö® **Important:**  \n",
        "- The function **does not overwrite existing files**.  \n",
        "- If re-running this block, **manually delete the existing output** to avoid conflicts.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4VQCqdpi2ua0",
      "metadata": {
        "id": "4VQCqdpi2ua0"
      },
      "outputs": [],
      "source": [
        "data = handle_predictions(\n",
        "    output_dir=output_dir,\n",
        "    method=method,\n",
        "    match_func=match_func,\n",
        "    results=results,\n",
        "    separation=separation,\n",
        "    orig=orig,\n",
        "    dat1=dat1,\n",
        "    dat2=dat2,\n",
        "    save=True,\n",
        "    load=True\n",
        ")\n",
        "\n",
        "# Access variables\n",
        "all_u = data['all_u']\n",
        "all_v = data['all_v']\n",
        "all_feature_points = data['all_feature_points']\n",
        "all_pkrs = data['all_pkrs']\n",
        "all_snrs = data['all_snrs']\n",
        "separation = data['separation']\n",
        "study_area_image = data['study_area_image']\n",
        "dat1 = data['dat1']\n",
        "dat2 = data['dat2']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "betNjykSnE3J",
      "metadata": {
        "id": "betNjykSnE3J"
      },
      "source": [
        "### **Pairwise Filtering**\n",
        "\n",
        "Refines feature tracking results by removing unreliable displacement vectors using several techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nmOeCkRmyY18",
      "metadata": {
        "id": "nmOeCkRmyY18"
      },
      "outputs": [],
      "source": [
        "# Run this after the cells above to set an alert sound when the processing is finished\n",
        "play_alert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "148oY261m-_n",
      "metadata": {
        "id": "148oY261m-_n"
      },
      "outputs": [],
      "source": [
        "# --- Filtering Parameters ---\n",
        "# These control which vectors are retained or removed post-tracking\n",
        "max_displacement = block_size - 1\n",
        "\n",
        "filter_params = {\n",
        "    \"apply_magnitude_filter\": True,          # Remove displacements below/above thresholds\n",
        "    \"min_magnitude\": 0,     # Minimum accepted motion\n",
        "    \"max_magnitude\": max_displacement,       # Maximum accepted motion (usually block_size - 1)\n",
        "    \"apply_zero_mask_filter\": False,         # Exclude pixels masked in any image (e.g., water/clouds)\n",
        "    \"apply_deviation_filter\": False,         # Remove vectors far from statistical mean\n",
        "    \"std_factor\": 2.5,                       # Standard deviation threshold for deviation filter\n",
        "    \"apply_remove_median_displacement\": True,  # Subtract overall median motion (e.g., camera jitter)\n",
        "    \"apply_median_filter_step\": False,       # Smooth vectors using a median filter\n",
        "    \"filter_size\": 5,                        # Size of median filter kernel (if used)\n",
        "    \"apply_angular_coherence_filter\": False, # Remove vectors that don‚Äôt align with dominant motion\n",
        "    \"angular_threshold\": 50,                 # Max angular deviation (degrees)\n",
        "    \"smoothing_sigma\": 1,                    # Angular coherence smoothing parameter\n",
        "    \"apply_erratic_displacement_filter\": False,  # Remove isolated, noisy vectors\n",
        "    \"neighborhood_size\": 20,                 # Radius for local filtering\n",
        "    \"deviation_threshold\": 2.0,              # Threshold for local deviation\n",
        "    \"apply_pkr_filter\": True,                # Remove low-quality matches using PKR\n",
        "    \"pkr_threshold\": 1.3,                    # Minimum accepted peak-to-residual ratio\n",
        "    \"apply_snr_filter\": True,                # Remove low-confidence vectors based on SNR\n",
        "    \"snr_threshold\": 3,                      # Minimum signal-to-noise ratio\n",
        "}\n",
        "\n",
        "filtered_all_u = []\n",
        "filtered_all_v = []\n",
        "filtered_all_feature_points = []\n",
        "\n",
        "for u, v, points, pkrs, snrs in zip(all_u, all_v, all_feature_points, all_pkrs, all_snrs):\n",
        "    # Convert to numpy arrays with proper numeric types\n",
        "    u = np.array(u, dtype=np.float64)\n",
        "    v = np.array(v, dtype=np.float64)\n",
        "    points = np.array(points, dtype=np.float64)\n",
        "    pkrs = np.array(pkrs, dtype=np.float64)\n",
        "    snrs = np.array(snrs, dtype=np.float64)\n",
        "\n",
        "    # Optionally, align pkrs and snrs with u if there is a mismatch.\n",
        "    if pkrs.shape[0] != u.shape[0]:\n",
        "        print(\"Aligning pkr values: original shape\", pkrs.shape, \"expected:\", u.shape)\n",
        "        pkrs = pkrs[:len(u)]\n",
        "    if snrs.shape[0] != u.shape[0]:\n",
        "        print(\"Aligning snr values: original shape\", snrs.shape, \"expected:\", u.shape)\n",
        "        snrs = snrs[:len(u)]\n",
        "\n",
        "    # Ensure zero_mask is an array if it exists (and has proper shape)\n",
        "    if zero_mask is not None:\n",
        "        zm = np.array(zero_mask)\n",
        "    else:\n",
        "        zm = None\n",
        "\n",
        "    # Try to apply filtering\n",
        "    try:\n",
        "        u_filtered, v_filtered, points_filtered = filter_displacements(\n",
        "            u, v, points, zm, pkr_values=pkrs, snr_values=snrs,\n",
        "            **filter_params\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"Error during filtering for one pair:\")\n",
        "        print(\"u:\", u)\n",
        "        print(\"v:\", v)\n",
        "        print(\"points:\", points)\n",
        "        print(\"pkrs:\", pkrs)\n",
        "        print(\"snrs:\", snrs)\n",
        "        raise e\n",
        "\n",
        "    filtered_all_u.append(u_filtered)\n",
        "    filtered_all_v.append(v_filtered)\n",
        "    filtered_all_feature_points.append(points_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shZ_j7tbtYrN",
      "metadata": {
        "id": "shZ_j7tbtYrN"
      },
      "source": [
        "### **Median Displacement Computation**  \n",
        "Aggregates filtered displacements across all image pairs, computes **median motion values** (displacement, magnitude, and direction), and visualizes the refined displacement field over the study area.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OVf9mrzym-7_",
      "metadata": {
        "id": "OVf9mrzym-7_"
      },
      "outputs": [],
      "source": [
        "pixel_size = 10   # Pixel resolution in meters\n",
        "apply_slope_correction=False # Correct estimates according to slope angle\n",
        "\n",
        "# Resample morpho image to match `study_area_image` shape\n",
        "morpho_path = f\"{output_dir}/morpho.tif\"\n",
        "output_path = f\"{output_dir}/resampled_morpho.tif\"\n",
        "resampled_morpho_path, resampled_transform = resample_morpho_to_match(study_area_image.shape, morpho_path, output_path)\n",
        "\n",
        "# Open and plot the resampled DEM, slope, and aspect\n",
        "with rasterio.open(resampled_morpho_path) as src:\n",
        "    resampled_dem = src.read(1)  # Band 1: Resampled DEM\n",
        "    resampled_slope = src.read(2)  # Band 2: Resampled slope\n",
        "    resampled_aspect = src.read(3)  # Band 3: Resampled aspect\n",
        "\n",
        "# Step 1: Accumulate Displacements\n",
        "displacement_data = accumulate_displacement(filtered_all_u, filtered_all_v, filtered_all_feature_points, separation)\n",
        "\n",
        "# Step 2: Calculate Median Displacement\n",
        "median_feature_points, median_u, median_v, median_magnitude, median_angles = calculate_median_displacement(displacement_data, pixel_size, slope_map=resampled_slope, apply_slope_correction=apply_slope_correction, normalize_by_time=True)\n",
        "\n",
        "plot_displacement_field(median_feature_points, median_u, median_v, median_magnitude, study_area_image, arrow_scale=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AT4g2-3Lt6Y8",
      "metadata": {
        "id": "AT4g2-3Lt6Y8"
      },
      "source": [
        "### **Final Displacement Filtering & Visualization**  \n",
        "Applies **terrain-based filters** (angular coherence, slope, aspect, clustering) to refine displacement data, removing weak or inconsistent movements. The DEM, slope, and aspect are resampled for accurate filtering, and the final **displacement field** is visualized.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3rgYSxGcm-2P",
      "metadata": {
        "id": "3rgYSxGcm-2P"
      },
      "outputs": [],
      "source": [
        "# Specify which filters to use & define parameters\n",
        "manual_threshold=None                   # If None, 95th percentile is used\n",
        "\n",
        "use_angular_coherence = True            # Use angular coherence filter\n",
        "angular_threshold_degrees = 30          # Angular threshold in degrees\n",
        "use_slope_filter = True                 # Skip slope filter\n",
        "min_slope_threshold = 5                 # Minimum slope in degrees\n",
        "use_aspect_filter = True                # Use aspect filter\n",
        "aspect_tolerance = 45                   # Allowable deviation from downslope direction in degrees\n",
        "use_clustering = True                   # Skip clustering filter\n",
        "clustering_params = (20, 9)             # Clustering parameters: (eps, min_samples)\n",
        "\n",
        "arrow_scale = 0.3                       # Scale of the vector arrow\n",
        "\n",
        "fil_median_feature_points, fil_median_u, fil_median_v, fil_median_magnitude = filter_final_map(\n",
        "    median_feature_points, median_u, median_v, median_magnitude, median_angles,\n",
        "    resampled_slope, resampled_aspect, study_area_image,\n",
        "    angular_threshold_degrees=angular_threshold_degrees, min_slope_threshold=min_slope_threshold,\n",
        "    aspect_tolerance=aspect_tolerance, smoothing_sigma=1, clustering_params=clustering_params,\n",
        "    use_angular_coherence=use_angular_coherence, use_slope_filter=use_slope_filter,\n",
        "    use_aspect_filter=use_aspect_filter, use_clustering=use_clustering, arrow_scale=arrow_scale,\n",
        "    manual_threshold=manual_threshold\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mqgYU9k1yYbv",
      "metadata": {
        "id": "mqgYU9k1yYbv"
      },
      "source": [
        "### **Generating & Saving Motion Colormap**  \n",
        "Creates a **refined displacement magnitude map**, overlays it on the composite image, and saves the result as `output_motion_colormap.tif` in GeoTIFF format, ensuring spatial alignment.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XBDIiRBgq5Ai",
      "metadata": {
        "id": "XBDIiRBgq5Ai"
      },
      "outputs": [],
      "source": [
        "# From cartesian to raster\n",
        "\n",
        "# filtered map\n",
        "fil_u_map, fil_v_map, fil_magnitude_map, fil_angle_map = create_raster_maps(\n",
        "    fil_median_feature_points, fil_median_u, fil_median_v, study_area_image, block_size, overlap\n",
        ")\n",
        "\n",
        "# full map\n",
        "u_map, v_map, magnitude_map, angle_map = create_raster_maps(\n",
        "    median_feature_points, median_u, median_v, study_area_image, block_size, overlap\n",
        ")\n",
        "\n",
        "processed_mask = process_mask(fil_magnitude_map)\n",
        "\n",
        "masked_magnitude = np.where(processed_mask, magnitude_map, np.nan)\n",
        "\n",
        "orig_path = f'{output_dir}/S2_Composite_Filtered_8bit.tif'\n",
        "output_path = f\"{output_dir}/output_motion_colormap.tif\"\n",
        "\n",
        "# Generate the magnitude map\n",
        "overlay_magnitude_map(orig[..., 0], masked_magnitude, block_size=block_size, overlap=overlap)\n",
        "\n",
        "save_as_geotiff(orig_path, output_path, masked_magnitude, block_size, overlap)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-mOJk3L7ycDA",
      "metadata": {
        "id": "-mOJk3L7ycDA"
      },
      "source": [
        "### **Time Series Reconstruction & Velocity Estimation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C4C3c4D3q-pG",
      "metadata": {
        "id": "C4C3c4D3q-pG"
      },
      "outputs": [],
      "source": [
        "cartesian_points = get_cartesian_points_from_mask(processed_mask, study_area_image.shape[:2])\n",
        "\n",
        "# Convert each row to a tuple for set operations.\n",
        "set_cartesian = set(map(tuple, cartesian_points))\n",
        "set_fil = set(map(tuple, median_feature_points))\n",
        "\n",
        "# Get the intersection (points that appear in both).\n",
        "common_points_set = set_cartesian.intersection(set_fil)\n",
        "\n",
        "# Convert back to a NumPy array.\n",
        "ts_points = np.array(list(common_points_set))\n",
        "\n",
        "displacement_data = accumulate_displacement_with_placeholders(\n",
        "    filtered_all_u, filtered_all_v, filtered_all_feature_points, separation, ts_points, dat1, dat2, pixel_size, all_pkrs, all_snrs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0026635",
      "metadata": {
        "id": "c0026635"
      },
      "source": [
        "\n",
        "Reconstructs pixel-wise displacement time series and estimates average velocity from pairwise results.\n",
        "\n",
        "üß† **Tip**: Use `'weighted'` for better handling of irregular observation frequency and variable data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vikVsfs3O1te",
      "metadata": {
        "id": "vikVsfs3O1te"
      },
      "outputs": [],
      "source": [
        "method = 'lsqr' # 'weighted' or 'midpoint' or 'lsqr'\n",
        "months_per_bin = 6\n",
        "min_snr=3\n",
        "min_pkr=1.3\n",
        "\n",
        "# the following are just for lsqr\n",
        "time_step='1M' # Solve for velocity every n months\n",
        "weight_by='snr' # Weight by snr or pkr ratio\n",
        "\n",
        "velocity_estimates = estimate_velocity_time_series(\n",
        "    displacement_data,\n",
        "    method=method,\n",
        "    months_per_bin=months_per_bin,\n",
        "    min_snr=min_snr,\n",
        "    min_pkr=min_pkr,\n",
        "    time_step=time_step,\n",
        "    weight_by=weight_by,\n",
        "    velocity_units='m/year'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gfMgQD9jdvmm",
      "metadata": {
        "id": "gfMgQD9jdvmm"
      },
      "source": [
        "Create Multiband .tif (creates 1 georeferenced map for each time step in the time series)\n",
        "\n",
        "Create a .gif time lapse of the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23984508",
      "metadata": {
        "id": "23984508"
      },
      "outputs": [],
      "source": [
        "tif_path = f\"{output_dir}/{output_dir}_magnitude_multiband.tif\"\n",
        "output_gif = f\"{output_dir}/{output_dir}_magnitude_multiband.gif\"\n",
        "\n",
        "create_multiband_magnitude_tif(velocity_estimates, study_area_image, output_dir, block_size, overlap, output_filename=f\"{output_dir}_magnitude_multiband.tif\")\n",
        "\n",
        "# study_area_image should be loaded as a NumPy array and have the same resolution as your composite.\n",
        "create_gif_with_background_and_colorbar(tif_path, study_area_image, output_gif, duration=1000.0, cmap=\"viridis\", alpha=0.6, velocity_estimates=velocity_estimates)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xmbc1c6jeCne",
      "metadata": {
        "id": "xmbc1c6jeCne"
      },
      "source": [
        "Save time series WE, NS and Magnitude in files compatible with InSAR Explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3cacb2",
      "metadata": {
        "id": "df3cacb2"
      },
      "outputs": [],
      "source": [
        "# Create velocity time series CSVs with median velocities for EW and SN components\n",
        "csv_data_we, csv_data_ns, csv_data_mag = prepare_csv_with_components(velocity_estimates, geotiff_path=f'{output_dir}/S2_Composite_Filtered_8bit.tif')\n",
        "\n",
        "# Save to CSV (optional)\n",
        "csv_data_we.to_csv(f'{output_dir}/velocity_time_series_we.csv', index=False)\n",
        "csv_data_ns.to_csv(f'{output_dir}/velocity_time_series_ns.csv', index=False)\n",
        "csv_data_mag.to_csv(f'{output_dir}/velocity_time_series_mag.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P7AjvNNZykUi",
      "metadata": {
        "id": "P7AjvNNZykUi"
      },
      "outputs": [],
      "source": [
        "# Plot fastes points\n",
        "plot_fastest_points_components(csv_data_we, csv_data_ns, top_n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LfThERh74RWa",
      "metadata": {
        "id": "LfThERh74RWa"
      },
      "source": [
        "### ‚¨áÔ∏è Downloading Outputs\n",
        "\n",
        "To download files directly from Colab to your computer. This creates a zip of the entire outputs folder and downloads it to device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HssiSFAbypwW",
      "metadata": {
        "id": "HssiSFAbypwW"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(f'Terratrack_Results_{output_dir}', 'zip', 'outputs')\n",
        "\n",
        "# Download\n",
        "files.download(f'Terratrack_Results_{output_dir}.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zs7guq8eTlRy",
      "metadata": {
        "id": "Zs7guq8eTlRy"
      },
      "outputs": [],
      "source": [
        "# Run this after the cells above to set an alert sound when the processing is finished\n",
        "play_alert()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Sgbckihq0fku",
      "metadata": {
        "id": "Sgbckihq0fku"
      },
      "source": [
        "# Inverse Velocity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uCPKxzm50iKU",
      "metadata": {
        "id": "uCPKxzm50iKU"
      },
      "outputs": [],
      "source": [
        "component = 'mag' # 'we', 'ns', 'mag'\n",
        "failure_dates_list = compute_inverse_velocity_failure_dates(f\"{output_dir}/velocity_time_series_{component}.csv\", n_points_for_fit_list=[3,4,5])\n",
        "failure_counts = failure_date_statistics(failure_dates_list)\n",
        "plot_failure_distribution(failure_counts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ee_ft",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
